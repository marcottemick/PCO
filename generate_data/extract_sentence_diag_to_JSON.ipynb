{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mysql.connector as mysqlpy\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_db_connection():\n",
    "    user = os.environ.get('DB_USER')\n",
    "    password = os.environ.get('DB_PASSWORD')\n",
    "    host = os.environ.get('DB_HOST')\n",
    "    port = os.environ.get('DB_PORT')\n",
    "    database = os.environ.get('DB_DATABASE')\n",
    "    bdd = mysqlpy.connect(user=user, password=password, host=host, port=port, database=database)\n",
    "    return bdd\n",
    "\n",
    "bdd = get_db_connection()\n",
    "cursor = bdd.cursor()\n",
    "cursor.execute(f'''SELECT CRO, id_diag, name, organe, diagnostic FROM CRO \n",
    "               JOIN patients USING (nir)\n",
    "               JOIN diagnostics USING (id_diag);''')\n",
    "CRO = cursor.fetchall()\n",
    "\n",
    "columns=[i[0] for i in cursor.description]\n",
    "\n",
    "CRO = pd.DataFrame(CRO, columns= columns)\n",
    "\n",
    "cursor.execute(f'''SELECT id_diag, diagnostic, organe FROM diagnostics;''')\n",
    "diag = cursor.fetchall()\n",
    "\n",
    "columns=[i[0] for i in cursor.description]\n",
    "\n",
    "diag = pd.DataFrame(diag, columns= columns)\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRO</th>\n",
       "      <th>id_diag</th>\n",
       "      <th>name</th>\n",
       "      <th>organe</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Résumé anatomo-pathologique\\nPatient : Gilbert...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gilbert Étienne</td>\n",
       "      <td>peau</td>\n",
       "      <td>lichen plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Résumé opératoire d'Histopathologie :\\nPatient...</td>\n",
       "      <td>2</td>\n",
       "      <td>Gilbert Étienne</td>\n",
       "      <td>peau</td>\n",
       "      <td>mélanome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Résumé anatomopathologique\\nPatient : Gilbert ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Gilbert Étienne</td>\n",
       "      <td>côlon</td>\n",
       "      <td>polypose adénomateuse familiale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Résumé anatomopathologique\\nPatient : Gilbert ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Gilbert Étienne</td>\n",
       "      <td>peau</td>\n",
       "      <td>mélanome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Résumé anatomopathologique\\nPatient : Joseph B...</td>\n",
       "      <td>16</td>\n",
       "      <td>Joseph Berthelot</td>\n",
       "      <td>côlon</td>\n",
       "      <td>tumeur neuroendocrine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CRO  id_diag  \\\n",
       "0  Résumé anatomo-pathologique\\nPatient : Gilbert...        5   \n",
       "1  Résumé opératoire d'Histopathologie :\\nPatient...        2   \n",
       "2  Résumé anatomopathologique\\nPatient : Gilbert ...       20   \n",
       "3  Résumé anatomopathologique\\nPatient : Gilbert ...        2   \n",
       "4  Résumé anatomopathologique\\nPatient : Joseph B...       16   \n",
       "\n",
       "               name organe                       diagnostic  \n",
       "0   Gilbert Étienne   peau                      lichen plan  \n",
       "1   Gilbert Étienne   peau                         mélanome  \n",
       "2   Gilbert Étienne  côlon  polypose adénomateuse familiale  \n",
       "3   Gilbert Étienne   peau                         mélanome  \n",
       "4  Joseph Berthelot  côlon            tumeur neuroendocrine  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRO.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_diag</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>organe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>psoriasis</td>\n",
       "      <td>peau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mélanome</td>\n",
       "      <td>peau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>rosacée</td>\n",
       "      <td>peau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>lupus érythémateux</td>\n",
       "      <td>peau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>lichen plan</td>\n",
       "      <td>peau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_diag          diagnostic organe\n",
       "0        1           psoriasis   peau\n",
       "1        2            mélanome   peau\n",
       "2        3             rosacée   peau\n",
       "3        4  lupus érythémateux   peau\n",
       "4        5         lichen plan   peau"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentence_with_diag(texte: str, diag: str, patient: str) -> dict:  \n",
    "    for rep in [f'chez {patient}', f'chez M {patient}', f'chez Mme {patient}', f'chez M {patient.split()[1]}', f'chez Mme {patient.split()[1]}']:\n",
    "        texte = texte.replace(rep, 'chez le patient')\n",
    "    for rep in [f'de {patient}', f\"d'{patient}\",  f'de M {patient}', f'de Mme {patient}', f'de M {patient.split()[1]}', f'de Mme {patient.split()[1]}']:\n",
    "        texte = texte.replace(rep, 'du patient')\n",
    "    for rep in [f'Le patient {patient}', f'le patient {patient}', f'la patient M {patient}', f'le patient M {patient.split()[1]}']:\n",
    "        texte = texte.replace(rep, 'le patient')\n",
    "    for rep in [f'sur {patient}', f'sur {patient.split()[1]}', f'sur M {patient}', f'sur M {patient.split()[1]}', f'sur Mme {patient}', f'sur Mme {patient.split()[1]}']:\n",
    "        texte = texte.replace(rep, 'le patient')  \n",
    "    text_split = texte.split('\\n')\n",
    "\n",
    "    occurrence = {}\n",
    "    for sentence in text_split:\n",
    "        index = -1\n",
    "        while True:\n",
    "            texte = sentence.lower()\n",
    "            # trouve toutes les occurences d'un mot dans le texte jusqu'à la fin\n",
    "            index = texte.find(diag.lower(), index + 1)\n",
    "            if index == -1:\n",
    "                break\n",
    "\n",
    "            index_fin = index + len(diag)\n",
    "\n",
    "            # vérifie par quoi se termine le mot pour éviter les mots dérivés du mot recherché\n",
    "            if texte[index_fin] in [' ', ',', '.', ')', ':']:                \n",
    "                occurrence = {'sentence': sentence, 'diag': diag}\n",
    "            else:\n",
    "                print(\"mot suivi d'une lettre\", diag, '\\n', sentence[index:])\n",
    "    return occurrence\n",
    "\n",
    "def find_sentence_without_diag(texte: str, diag: str) -> list:\n",
    "    text_split = texte.split('\\n')\n",
    "    for paragraphe in text_split:\n",
    "        if diag.lower() not in paragraphe.lower():\n",
    "             if len(paragraphe) >= 200:\n",
    "                return paragraphe\n",
    "\n",
    "def sentence_version(dict_sentences: dict) -> list:\n",
    "        sentences_list = dict_sentences['sentence']\n",
    "        sentences_list = sentences_list.split('.')\n",
    "        for sentence in sentences_list:\n",
    "             if dict_sentences['diag'] in sentence:\n",
    "                sentence_split = sentence.split(dict_sentences['diag'])\n",
    "                sentence_before_diag = sentence_split[0] \n",
    "                sentence_after_diag = sentence_split[1]\n",
    "                sentence_list = sentence_before_diag.split() \n",
    "                if sentence_list[len(sentence_list) -1] == 'la' or sentence_list[len(sentence_list) -1] == 'le' or sentence_list[len(sentence_list) -1] == 'un' or sentence_list[len(sentence_list) -1] == 'une':\n",
    "                    sentence_list = sentence_list[0: len(sentence_list) - 1]\n",
    "                    sentence_before_diag = \" \".join(sentence_list) + \" un \"\n",
    "                if sentence_list[len(sentence_list) -1] == \"d'un\" or sentence_list[len(sentence_list) -1] == \"d'une\":\n",
    "                    sentence_list = sentence_list[0: len(sentence_list) - 1]\n",
    "                    sentence = \" \".join(sentence_list) + \" d'un \"\n",
    "                sentence_before_diag = sentence_before_diag + '[[DIAG]]'                 \n",
    "\n",
    "                return sentence_before_diag, sentence_after_diag\n",
    "        return \"\", \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_of_sentences_diag(CRO: pd.DataFrame, diag: pd.DataFrame, data: str) -> list:\n",
    "    random.seed(0)\n",
    "    \n",
    "    # stocke les paragraphes contenant les diagnostics et les diagnostics présents dans le CRO\n",
    "    paragraphes = []\n",
    "    paragraphes_sans_diag = []\n",
    "    for n in range(0, len(CRO)):\n",
    "        paragraphes.append(find_sentence_with_diag(CRO.CRO[n], CRO.diagnostic[n], CRO.name[n]))\n",
    "        paragraphes_sans_diag.append(find_sentence_without_diag(CRO.CRO[n], CRO.diagnostic[n]))\n",
    "    # stocke les phrases qui contient la diagnostic en vérifiant leur absence au préalable\n",
    "    sentences_before_diag = []\n",
    "    sentences_after_diag = []\n",
    "    \n",
    "    for resp in paragraphes:\n",
    "        sentence_before_diag, sentence_after_diag = sentence_version(resp)\n",
    "        if sentence_before_diag not in sentences_before_diag:                          \n",
    "            sentences_before_diag.append(sentence_before_diag)        \n",
    "        sentences_after_diag.append(sentence_after_diag)\n",
    "    random.shuffle(sentences_after_diag)\n",
    "\n",
    "    # génère une liste de diagnostics de la même longueur que le nombre de phrase unique repérée\n",
    "    symbole = '=' if data == 'test' else '!'\n",
    "    diags_list = pd.read_csv('..\\data\\diagnostics_extend.csv', sep=';')\n",
    "    diags_list = diags_list.query(f'organe {symbole}= \"foie\"')\n",
    "\n",
    "    diags_list = diags_list.diagnostic.unique().tolist()\n",
    "    nb_sentences = len(sentences_before_diag)\n",
    "    facteur_mulitplicateur = nb_sentences // len(diags_list)\n",
    "    diags_list_multi = diags_list * facteur_mulitplicateur\n",
    "    random.shuffle(diags_list_multi)\n",
    "    diags_list_complement = diags_list\n",
    "    random.shuffle(diags_list_complement)\n",
    "    manque = len(sentences_before_diag) - len(diags_list_multi)\n",
    "    diags_list_multi = diags_list_multi + diags_list_complement[0: manque]\n",
    "\n",
    "    # remplace les diagnostics présents dans les phrases retenues\n",
    "    sentences_with_diags = []\n",
    "    for n in range(0, len(sentences_before_diag)):\n",
    "        sentence = sentences_before_diag[n].replace('[[DIAG]]', diags_list_multi[n])\n",
    "        sentences_with_diags.append({'text' : sentence, 'diag': diags_list_multi[n]})\n",
    "\n",
    "    # remplace les phrases contenants les diagnostics dans les paragraphes retenus\n",
    "    for sentences in paragraphes:\n",
    "        sentences_list = sentences['sentence'].split('.')\n",
    "        for n in range(0, len(sentences_list)):\n",
    "            if sentences['diag'] in sentences_list[n]:\n",
    "                sentences_list[n] = ' [[SENTENCE]]'\n",
    "        sentences['sentence'] = '.'.join(sentences_list)\n",
    "\n",
    "    random.shuffle(paragraphes)\n",
    "\n",
    "    # remplace les phrases présent initialement dans le paragraphe par une phrase unique\n",
    "    new_paragraphes = []\n",
    "    for n in range(0, len(sentences_with_diags)):\n",
    "        sentences = paragraphes[n]['sentence'].strip()\n",
    "        diag = sentences_with_diags[n]['diag']\n",
    "        sentences = sentences.replace('[[SENTENCE]]', sentences_with_diags[n]['text'])\n",
    "        index_debut = sentences.find(diag)\n",
    "        index_fin = index_debut + len(diag)\n",
    "        new_paragraphes.append([sentences, {'entities': [[index_debut, index_fin, 'DIAG']]}])\n",
    "    \n",
    "    if data != 'test':\n",
    "        nb_paragraphes_without_diag = int(len(new_paragraphes) * 10 / 100)\n",
    "        print(len(paragraphes_sans_diag))\n",
    "        random.shuffle(paragraphes_sans_diag)\n",
    "        paragraphes_sans_diag = paragraphes_sans_diag[0 : nb_paragraphes_without_diag - 1]\n",
    "        for paragraphe in paragraphes_sans_diag:\n",
    "            if paragraphe is not None:\n",
    "                new_paragraphes.append([paragraphe, {'entities': []}])\n",
    "\n",
    "    random.shuffle(new_paragraphes)\n",
    "\n",
    "    return new_paragraphes\n",
    "\n",
    "def csv_to_json(list_of_sentences: list, file_json : Path) -> str:\n",
    "    '''\n",
    "    Génération d'un fichier JSON qui rassemble le texte, les index de début et de fin de chaque mot associé à leur label\n",
    "    - entrées : \n",
    "    - sortie : un fichier JSON\n",
    "    '''\n",
    "    # ouverture du fichier JSON\n",
    "    to_json = json.dumps(list_of_sentences, ensure_ascii=False)\n",
    "\n",
    "    with open(file_json, 'w', encoding=\"utf-8\") as fichier:\n",
    "        # écriture du fichier JSON, ajout si existe déjà !\n",
    "        fichier.write(to_json)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mot suivi d'une lettre diverticulite \n",
      " diverticulites. Il s'agissait principalement de diverticules simplex localisés aux bords du spécimen. Des zones d'inflammation aiguë avec infiltrat polynucléaire neutrophile (PN) abondant et dégranulation des mastocytes ont été observées. Les cryptes intestinales restaient intactes. Aucune atteinte dysplasique ou cancerienne n'a été identifiée.\n",
      "1712\n",
      "mot suivi d'une lettre diverticulite \n",
      " diverticulites de suivre une alimentation riche en fibres pour prévenir la formation de complications telles qu'une perforation ou une infection. Un contrôle régulier devrait être considéré pour surveiller l'évolution de cette pathologie.\n",
      "428\n",
      "mot suivi d'une lettre cholangiocarcinome \n",
      " cholangiocarcinomes.\n",
      "mot suivi d'une lettre hépatoblastome \n",
      " hépatoblastomes. Des foci de différentiation hépatocytaires sont observés dans certaines sections, avec des cellules hépatiques matures et des biles canaliculaires bien formées. Cependant, des zones ne montrent pas de différenciation hépatocytique et contiennent des cellules embryonnaires immatures. Les vaisseaux sanguins intratumoraux sont dilatés et infiltrés par des cellules tumorales. Une zone centrale nécrotique est également présente.\n",
      "génération du fichier json train\n",
      "La data train possède 1142\n",
      "génération du fichier json valid\n",
      "La data valid possède 364\n",
      "génération du fichier json test\n",
      "La data test possède 141\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "CRO_train_valid = CRO.query('organe != \"foie\"').reset_index(drop=True)\n",
    "CRO_test = CRO.query('organe == \"foie\"').reset_index(drop=True)\n",
    "\n",
    "CRO_train, CRO_valid = train_test_split(CRO_train_valid, test_size=0.2, stratify=CRO_train_valid['id_diag'], random_state=42)\n",
    "CRO_train= CRO_train.reset_index(drop=True)\n",
    "CRO_valid = CRO_valid.reset_index(drop=True)\n",
    "\n",
    "train_data = generate_list_of_sentences_diag(CRO_train, diag, 'train')\n",
    "valid_data = generate_list_of_sentences_diag(CRO_valid, diag, 'valid')\n",
    "test_data= generate_list_of_sentences_diag(CRO_test, diag, 'test')\n",
    "\n",
    "print('génération du fichier json train')\n",
    "taille_json_train = csv_to_json(train_data, '../generate_model/assets/train.json')\n",
    "print(f'La data train possède {len(train_data)}')\n",
    "\n",
    "print('génération du fichier json valid')\n",
    "taille_json_valid = csv_to_json(valid_data, '../generate_model/assets/dev.json')\n",
    "print(f'La data valid possède {len(valid_data)}')\n",
    "\n",
    "print('génération du fichier json test')\n",
    "taille_json_test = csv_to_json(test_data, '../generate_model/assets/test.json')\n",
    "print(f'La data test possède {len(test_data)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
